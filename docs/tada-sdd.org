* About this document
This document is intended for system software developers and
maintainers.  It may also be shared with decision makers to provide
a common context including requirements, goals, and plans.

* Overview
This System Design Document (SDD) attempts to describe software as
built. Since the document and software are being written at the same
time, the may not match until the project is completed.

The software described is: /TADA (Telescope Automatic Data Archiver)/
The purpose of TADA is to provide an end-to-end flow of data from
telescope instruments to archives at machines around the world. By its
very nature, TADA is a multi-machine system. 

The project must proceed without the benefit of known
requirements. Therefore, development will proceed with a series of
alpha releases that represent various "threads through the system".
Each thread may contain arbitrary amounts of mockup code but will at
the very least simulate the end-to-end flow of data.  Later
alpha-versions will contain progressively more real (non-mockup)
components. The first beta release will contain no-mockup for the
thread but may contain mocked up modules on either side of the
thread. e.g. A mockup will pretend to be telescope instruments sending
data. 

At each alpha-release, stake-holders have the opportunity to affect
what is done for the next release.  Its *very important* for
stake-holders to provide prompt feedback.  In the absence of such
feedback, developers will simply guess on what is important next and
move on.  

* Sprint user stories
These are the expect outcomes from progressively more complex [[https://www.scrum.org/][scrum]] sprints.

In our case "user" means two kinds of people: 
  1. scientist that want access to data,
  2. SDM DevOps employees that need to manage the process

** Thread-1: Establishes file move to archive and test
This is minimal "thread through the system" starting at raw-data and
terminating with files in the archive.
- [X] mock-LPR;  Feed each file in list to Ingest after specified delay
- [X] Ingest;  Copy file into mock-IRODS (a local filesystem)
- [ ] Test;  Verify all input files are  in mock-IRODS

*** 
#+BEGIN_SRC dot :file figures/thread1.png :cmdline -Tpng :tangle src-tangles/thread1.dot
  digraph thread1 {
      rankdir="LR";
      edge [len=1.0];
      raw [shape="invhouse"];
      expected [label="Expected\n(raw)", shape="invhouse"];
      report [shape="house"];

      raw -> mockLpr -> ingest -> archive -> test;
      timing -> mockLpr;
      expected -> test -> report;
  }
#+END_SRC

** Thread-2: Touches FITS data  (verifies selected metadata in archive)
- [ ] all of Thread-1
- [ ] insure minimum (level 0) set of required metadata fields in FITS
  + minimum acceptable for archive
- [ ] Test;  Verify all files in mock-IRODS contain required metadata 

*** 
#+BEGIN_SRC dot :file figures/thread2.png :cmdline -Tpng :tangle src-tangles/thread2.dot
  digraph thread2 {
      rankdir="LR";
      edge [len=1.0];
      raw [shape="invhouse"];
      expected [label="Expected\n(cooked)", shape="invhouse", fontcolor="green"];
      report [shape="house"];

      raw -> mockLpr -> ingest;
      ingest -> archive [label="insert metadata", fontcolor="green"];
      archive -> test;
      timing -> mockLpr;
      expected -> test -> report;
   }
#+END_SRC

** Thread-3: Split into 2 machines, use iRODS client/server
- [ ] mock-LPR;  Feed each file in list to Ingest after specified delay
- [ ] Ingest; add file to iRODS[fn:3] on remote machine
- [ ] Test;  Verify all iRODS filesystem contains everything from orig filesystem
*** 
#+BEGIN_SRC dot :file figures/thread3.png :cmdline -Tpng :tangle src-tangles/thread3.dot
  digraph thread3 {
      rankdir="LR";
      edge [len=1.0];
      raw [shape="invhouse"];
      expected [label="Expected\n(cooked)", shape="invhouse", fontcolor="green"];
      report [shape="house"];
      archive [label="Archive\n(iRODS)", shape="box"];

      subgraph cluster_mountain {
        label = "Mountain";
        style="dashed";

        timing -> mockLpr;
        raw -> mockLpr -> ingest;
      }

      subgraph cluster_valley {
        label = "Valley";
        style="dashed";

        ingest -> archive [label="iCommands", fontcolor="green"];
        archive -> test;
        expected -> test -> report;
      }
   }
#+END_SRC

** LATER
- easy to add plugins for scientists 
  + scientist provides program to run against (filtered) set of
    images, stores "result" file accessable in archive

* Assumptions
- Number of users of an instances of this system is very small (under
  20).  "Users" in this case are data-managent operators of some
  sort.  People that make sure the data is still flowing and correct
  problems as they come up (which should be very rare).
  
* Goals
** Prove its done right
To PROVE we have it right[fn:1], we need good monitoring. To support
courageous code changes, the monitoring should be nearly identical
between:
- production
- developmental (to be deployed) system (on VMs or real machines)
- under DES (Discrete Event Simulation)[fn:2]
  [[~/sandbox/dfsim/dfsim.py][dfsim]]

*** Simulation                                                     :noexport:
It would be GREAT to generally connect simulator to data-flow graph
display. What tools?  Need graphics that support drawing graph and can
hilite nodes. tcl/tk?  Is there something in latest networkx that
helps? Perhaps I need to write a general OSS project.  Lauch with
graph. It draws.  Pipe in for commands (hilite, others?). Pipe out for
state?

*** Monitor display                                                :noexport:
Plots from DES (gnu plot?) to represent values of resources (queue
size).  Alerts for when thresholds exceeded. (queue max size reached)
Utilization measures.

* Requirements                                                       :export:
** General systemic requirements
1. Provide all required the functionality of system this replaces
2. Resilient 
   - don't break -- EVER
3. Maintainable
   - by new employees without large learning curve
4. Operate fast enough (need quantification)


** Candidate requirements
These requirements have *not been committed to*.  In many case they
need to be made more precise.

- All database clients must be capable of reconnecting to database
  servers on connection loss (so components can be restarted)
- Increase level of automation of regular operation functions
- use version control always; with commit comments
- elliminate direct changes to live production system (from tagged version)
- (document minimumaly acceptable coding style)
- Implement regression testing (automated where possible, documented otherwise)
- write design documentation
- write installation documentation
- write usage documentation
- reproducible installs
- daily operations must not require manual intervention
- daily operations must not require human monitoring (automatic alerts instead)
- eliminate metadata remmediation in its present form (what form???)
  + get metadata from file format, or
  + get metadata from TO/observer/observatory support staff at data
    collection time
- insert "archival metadata" just before final archiving (???)
- insert of archival metadata should be idempotent
- eliminate mountain copy coherency requirement (???)
- filename agnostic; nothing in the system should depend on the
  structure or uniqueness of a filename
- limit access to internals connection points (ports, databases)
  + perhaps by host, port, user
- literate programming: data flow software and config files: must be
  able to auto generate a document that describes the flow (including
  connectivity or data-flow diagram).

** simulator requirements (DES)                                    :noexport:
*** First
- process for 
  + [X] DataQ
  + [X] Action
  + [X] Instrument
  + [X] monitorQ
  + [ ] externals
- Collect "final answers" for comparision to non-sim
- Support random failures (for Action)

*** Later
- specify as graph
- literate programming; spec (graph) generates code and doc
- probes at any junction (How do I specify?)
- hilite "active edge" (when data is flowing through it)




** Meta data required for ingest into archive
- [ ] PROPID
- [ ] DATE-OBS
- [ ] DTTITLE
- [ ] DTACQNAM
- [ ] DTNSANAM
- [ ] DTINSTRU
- [ ] DTTELESC
- [ ] DTSITE
- [ ] DTUTC
- [ ] DTPI
- [ ] DTSITE

from https://support.sdm.noao.edu/browse/OPS-1991


** MVP - Minimally Viable Product
These are the absolute minium requirements for a DCI replacement.
When ever possible, avoid putting anything here that is an absolutely
essential requirement. (push "would be nice" stuff into subsequent
release)

1. Baring fatal hardware failure, every file produced by instrument
   gets into archive
2. 

** Release 2
1. Each site is "independent"
   + What is a "site"?
   + How independent do they have to be? (archive depends on telescope,
     for instance)
2. Must be able to re-route around broken machines
3. Allow institutions direct access to iRODS data ("back-door")

** Deferred requirements
- *Dashboard* for monitoring health of TADA system
  - web based
* Open Issues
** Which files from input list ("printed" files) should get moved to archive?
  - [ ] All of them?
  - [ ] *.fits.fz?
  - [ ] *.fits?
  - [ ] *.hdr
  - DEFAULT ANSWER: only *.fitz.fz
** What if FITS files do NOT contain minimum required metadata (fields/values)?
  - Insert dummy (not realistic) values.
  - Calculate values. How?
  - Reject file (report and do not archive)
  - DEFAULT ANSWER: Reject file

* Closed Issues

* New Name
** Possible names for DCI replacement
- [ ] MADI :: Mountain Archive Data Initiative
- [ ] MATT :: Mountain Archive Telescope Transport
- [ ] ADAM :: Archive Data Automated Mover
- [X] TADA :: Telescope Automatic Data Archiver
- [ ] MAMA :: Mountain Automated Moving Archive
- [ ] TATO :: Telecsope Archive Transport Operation
- [ ] DRAT :: Data Relay Archive Transporter
- [ ] MAMI :: Mountain Archive Mover Initiative
- [ ] MOTA :: MOuntain To Archive
- [ ] STARI :: Send Telescope Archive Relay Initiative
- [ ] STARE :: Send Telescope data via RElay

** COMMENT Keyword terms for acro
archive
automated
data
initiative
irods
mountain
mover
operation
relay
send
telescope
transport



* Release checklist
** Maintainability 
- [ ] Documentation as built
- [ ] Requirements addressed in software as built
- [ ] Tests
- [ ] Configuration Management
- [ ] Auto provisioning of everything I develop
- [ ] Documentation of existing system

* Secondary Goals
My primary goal is to develop useful software.  Exactly what that
software will be is unfolding.  It has to be an iterative process. But
regardless of what the software is, there are some secondary goals
that go along with it. Here are most of them:

1. Documentation as built

   My intent is to provide "as built" design and code documentation. Code
   documentation will be generated directly from annotated code. Design
   docs will be hand written, with diagrams.  It will include example
   runs with inputs and outputs listed. The intended reader for both is
   someone that is software tech savvy.

2. Requirements addressed in software as built

   Whatever I develop is intended to address some requirements that I
   have in mind.  I'll put those down in a document.  These may be
   different than any requirements anyone gives to me because they will
   be directly focused on functionality of the software I develop, rather
   than on a larger system perspective (which I may have little control
   over). The intended reader is management and/or software engineer.

3. Tests

   Each package I write has a "smoke test".  This is a simple script that
   can be run by anyone after the software is installed to see that it
   works in some fashion.  My smoke tests are not exhaustive regression
   tests.  They are intended to be used by developers to ask the
   question: "did I break anything with the last change". Smoke tests
   include their own test data and are checked into configuration
   management with the code.

4. Configuration Management

   All my software will be checked into github or bitbucket. Related
   documentation will be included with the code.

5. Auto provisioning of everything I develop

   I'll provide a "vagrant box", or similar, for all my stuff.  This will
   allow a new Virtual Machine(s) to be created from scratch and all my
   stuff installed on it such that my smoke tests will work on the new
   VM(s).

6. Documentation of existing system

   In the process of figuring out what my new stuff has to do, I have to
   figure out what the existing stuff does. I don't want to attempt to
   hold all that in my head, so I document it.  You've all seen at least
   part of my DCI "notes". That is basically the source of what I'm
   talking about here.  I don't intend to formalize it any way unless
   forced into it. I think it would be too time-consuming/expensive for
   me to do and I think I have more the enough technical work on my
   plate.  But I will provide at least a crude extraction from my notes
   to something that might be useful to others.  The effort I put into
   such depends on feedback from you. No feedback means I'll provide
   something that is a similar level of informality as the notes I've
   already shared with you. I've already exported some parts of that
   (like my diagram) to the opswiki.


---------
* Footnotes

[fn:1] SDM is responsibly managing data, nothing is being lost, its
going where it should, rates and sizes of data are as expected, manual
intervention is not required except in the most unusual circumstances
(expected 2-4 times per YEAR). Code changes can be made with courage
without doubt or fear of breaking something.

[fn:2] https://simpy.readthedocs.org/en/latest/

[fn:3] [[http://irods.org][iRODS]] 4*;  4.0 was release April 4, 2014; 4.0.3 released Aug
20, 2014

* COMMENT POSTSCRIPT
/(this section here to keep Document Comments out of the way)/
source: /home/pothiers/orgfiles/designs.org

Something like this can be inserted into doc by invoking export dispatcher
and selected "insert template" (C-c C-e #).


#+TITLE:   TADA (Telescope Automatic Data Archiver) SDD
#+AUTHOR:    Steve Pothier
#+EMAIL:     pothier@noao.edu
#+KEYWORDS: 
#+LANGUAGE:  en
#+OPTIONS:   H:3 num:nil toc:t \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:nil
#+INFOJS_OPT: view:nil toc:t ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:   
#+LINK_HOME: 
#+XSLT: 


